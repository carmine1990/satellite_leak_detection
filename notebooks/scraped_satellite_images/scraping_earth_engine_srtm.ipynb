{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dati Satellite SRTM (dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-16T06:09:41.986296Z",
     "start_time": "2017-03-16T14:09:40.699962+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.4f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from path import Path\n",
    "import arrow\n",
    "import json\n",
    "import pytz\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "import re, os, collections, itertools, uuid, logging\n",
    "import tempfile\n",
    "import shapely\n",
    "\n",
    "import zipfile\n",
    "import urllib\n",
    "\n",
    "import ee\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 5) # bigger plots\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "%precision 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-16T06:09:45.232506Z",
     "start_time": "2017-03-16T14:09:42.052595+08:00"
    }
   },
   "outputs": [],
   "source": [
    "helper_dir = str(Path('..').abspath())\n",
    "if helper_dir not in os.sys.path:\n",
    "    os.sys.path.append(helper_dir)\n",
    "    \n",
    "from leak_helpers.earth_engine import display_ee, get_boundary, tifs2np, bands_srtm, download_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-16T06:09:45.237820Z",
     "start_time": "2017-03-16T14:09:45.234693+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# # Non voglio stampare i Warning\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-06T13:43:10.906470",
     "start_time": "2017-03-06T13:43:10.867216"
    },
    "collapsed": true
   },
   "source": [
    "# Load leaks\n",
    "\n",
    "Load the leaks from a geojson file and make sure they have unique fields reportdate and workorderid (see asserts below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         id  anno civico      comune  comune_loc  \\\n",
       " 0         0  2015      0   PODENZANA   PODENZANA   \n",
       " 1         1  2015      1     TRESANA     TRESANA   \n",
       " 2         3  2015     00  pontremoli  PONTREMOLI   \n",
       " 3         9  2016         pontremoli  PONTREMOLI   \n",
       " 4        44  2021   None  PONTREMOLI  PONTREMOLI   \n",
       " ...     ...   ...    ...         ...         ...   \n",
       " 1708  34754  2021     51    CAMAIORE    CAMAIORE   \n",
       " 1709  34760  2021   None    CAMAIORE    CAMAIORE   \n",
       " 1710  34873  2021   None   MASSAROSA   MASSAROSA   \n",
       " 1711  34881  2021     24  FILATTIERA  FILATTIERA   \n",
       " 1712  35025  2022   None   MASSAROSA   MASSAROSA   \n",
       " \n",
       "                                             description  diametro  \\\n",
       " 0       Perdita acqua dalla rete montedivalli podenzana     110.0   \n",
       " 1     perdita su adduttrice serbatoio giovagallo ese...      90.0   \n",
       " 2       rotture idriche addutrice serbatoio di s. marco     125.0   \n",
       " 3                                      PERDITA STRADALE     110.0   \n",
       " 4     Mancata fornitura idrica- PERDITA ACQUA DALLA ...      90.0   \n",
       " ...                                                 ...       ...   \n",
       " 1708                    Perdita via quattro novembre 51      90.0   \n",
       " 1709                           perdita acqua dalla rete      90.0   \n",
       " 1710         Perdita di acqua vista da nostro personale     125.0   \n",
       " 1711                                   PERDITA STRADALE      90.0   \n",
       " 1712                           Perdita acqua dalla rete     100.0   \n",
       " \n",
       "       l_intervento                       localita  location  ... objectid  \\\n",
       " 0              0.0                      PODENZANA  38A05A01  ...        0   \n",
       " 1              0.0                        TRESANA  45A07A04  ...        1   \n",
       " 2              0.0                        BASSONE  39A01A18  ...        3   \n",
       " 3              0.0                        DOZZANO  39A01A04  ...        9   \n",
       " 4              0.0  LOCALITA' COSTA S. NICOLO' 23  39A01A08  ...       44   \n",
       " ...            ...                            ...       ...  ...      ...   \n",
       " 1708           0.0                CAMAIORE CENTRO  07A01R05  ...    34754   \n",
       " 1709           0.0                CAMAIORE CENTRO  07A01R05  ...    34760   \n",
       " 1710           0.0             PIAN DEL QUERCIONE  28A01R08  ...    34873   \n",
       " 1711           0.0                     FILATTIERA  18A01R01  ...    34881   \n",
       " 1712           0.0                     BARGECCHIA  28A01R03  ...    35025   \n",
       " \n",
       "                             reportdate serv_cost  status  \\\n",
       " 0            2015-05-15T16:14:00+00:00    286.57   CLOSE   \n",
       " 1            2015-05-30T17:14:00+00:00    220.99   CLOSE   \n",
       " 2     2015-09-08T06:34:01.403000+00:00    645.88   CLOSE   \n",
       " 3     2016-09-05T11:59:11.637000+00:00    539.55   CLOSE   \n",
       " 4            2021-07-17T05:44:00+00:00   1057.92   CLOSE   \n",
       " ...                                ...       ...     ...   \n",
       " 1708  2021-07-16T05:40:11.870000+00:00    411.85   CLOSE   \n",
       " 1709         2021-07-19T04:50:00+00:00    607.40   CLOSE   \n",
       " 1710  2021-09-04T15:13:31.657000+00:00    776.14   CLOSE   \n",
       " 1711  2021-09-07T09:46:49.459999+00:00    653.46   CLOSE   \n",
       " 1712         2022-01-30T11:30:00+00:00    725.97   CLOSE   \n",
       " \n",
       "                                                 via        wonum workorderid  \\\n",
       " 0                                          Genova 0  15ODL105517      434549   \n",
       " 1                                        VIA BOLA 1  15ODL121318      449895   \n",
       " 2                                           bassone  15ODL198239      526117   \n",
       " 3                                           dozzano  16ODL315760      815762   \n",
       " 4                     LOCALITA' COSTA S. NICOLO' 23  21ODL308113     2621776   \n",
       " ...                                             ...          ...         ...   \n",
       " 1708                            quattro novembre 51  21ODL307918     2621532   \n",
       " 1709                               VIA DI MEZZO 102  21ODL312931     2626643   \n",
       " 1710                                     Montramito  21ODL359928     2674832   \n",
       " 1711                               PONTE PROVINCILE  21ODL364825     2679778   \n",
       " 1712  VIA DELLE SEZIONI 4480 Scala    Piano    Int.  22ODL138779     2834360   \n",
       " \n",
       "                  x             y                   geometry  \n",
       " 0     1.097467e+06  5.495690e+06   POINT (9.85871 44.19513)  \n",
       " 1     1.099411e+06  5.502049e+06   POINT (9.87618 44.23608)  \n",
       " 2     1.096196e+06  5.524731e+06   POINT (9.84730 44.38188)  \n",
       " 3     1.098026e+06  5.522370e+06   POINT (9.86374 44.36673)  \n",
       " 4     1.095851e+06  5.525300e+06   POINT (9.84420 44.38554)  \n",
       " ...            ...           ...                        ...  \n",
       " 1708  1.147021e+06  5.455793e+06  POINT (10.30386 43.93762)  \n",
       " 1709  1.146962e+06  5.457335e+06  POINT (10.30334 43.94759)  \n",
       " 1710  1.146499e+06  5.447423e+06  POINT (10.29917 43.88345)  \n",
       " 1711  1.105849e+06  5.516756e+06   POINT (9.93401 44.33066)  \n",
       " 1712  1.146617e+06  5.449781e+06  POINT (10.30023 43.89871)  \n",
       " \n",
       " [1713 rows x 21 columns]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load \n",
    "root = \"../../../ricerca_perdite\"\n",
    "leaks = gpd.read_file(root+\"/data/leak_dataset/leaks.geojson\")\n",
    "\n",
    "leaks_datas = [leaks]\n",
    "\n",
    "leaks_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TRANFA~1.CAR\\AppData\\Local\\Temp/ipykernel_8136/3025104378.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  leaks['metadata'] = np.concatenate([leaks_data.drop(primary_cols,1).to_dict('records') for leaks_data in leaks_datas])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workorderid</th>\n",
       "      <th>reportdate</th>\n",
       "      <th>geometry</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workorderid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434549</th>\n",
       "      <td>434549</td>\n",
       "      <td>2015-05-15T16:14:00+00:00</td>\n",
       "      <td>POINT (9.85871 44.19513)</td>\n",
       "      <td>{'id': '0', 'anno': 2015, 'civico': '0', 'comu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449895</th>\n",
       "      <td>449895</td>\n",
       "      <td>2015-05-30T17:14:00+00:00</td>\n",
       "      <td>POINT (9.87618 44.23608)</td>\n",
       "      <td>{'id': '1', 'anno': 2015, 'civico': '1', 'comu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526117</th>\n",
       "      <td>526117</td>\n",
       "      <td>2015-09-08T06:34:01.403000+00:00</td>\n",
       "      <td>POINT (9.84730 44.38188)</td>\n",
       "      <td>{'id': '3', 'anno': 2015, 'civico': '00', 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815762</th>\n",
       "      <td>815762</td>\n",
       "      <td>2016-09-05T11:59:11.637000+00:00</td>\n",
       "      <td>POINT (9.86374 44.36673)</td>\n",
       "      <td>{'id': '9', 'anno': 2016, 'civico': '', 'comun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621776</th>\n",
       "      <td>2621776</td>\n",
       "      <td>2021-07-17T05:44:00+00:00</td>\n",
       "      <td>POINT (9.84420 44.38554)</td>\n",
       "      <td>{'id': '44', 'anno': 2021, 'civico': None, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621532</th>\n",
       "      <td>2621532</td>\n",
       "      <td>2021-07-16T05:40:11.870000+00:00</td>\n",
       "      <td>POINT (10.30386 43.93762)</td>\n",
       "      <td>{'id': '34754', 'anno': 2021, 'civico': '51', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626643</th>\n",
       "      <td>2626643</td>\n",
       "      <td>2021-07-19T04:50:00+00:00</td>\n",
       "      <td>POINT (10.30334 43.94759)</td>\n",
       "      <td>{'id': '34760', 'anno': 2021, 'civico': None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674832</th>\n",
       "      <td>2674832</td>\n",
       "      <td>2021-09-04T15:13:31.657000+00:00</td>\n",
       "      <td>POINT (10.29917 43.88345)</td>\n",
       "      <td>{'id': '34873', 'anno': 2021, 'civico': None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679778</th>\n",
       "      <td>2679778</td>\n",
       "      <td>2021-09-07T09:46:49.459999+00:00</td>\n",
       "      <td>POINT (9.93401 44.33066)</td>\n",
       "      <td>{'id': '34881', 'anno': 2021, 'civico': '24', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834360</th>\n",
       "      <td>2834360</td>\n",
       "      <td>2022-01-30T11:30:00+00:00</td>\n",
       "      <td>POINT (10.30023 43.89871)</td>\n",
       "      <td>{'id': '35025', 'anno': 2022, 'civico': None, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1713 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             workorderid                        reportdate  \\\n",
       "workorderid                                                  \n",
       "434549            434549         2015-05-15T16:14:00+00:00   \n",
       "449895            449895         2015-05-30T17:14:00+00:00   \n",
       "526117            526117  2015-09-08T06:34:01.403000+00:00   \n",
       "815762            815762  2016-09-05T11:59:11.637000+00:00   \n",
       "2621776          2621776         2021-07-17T05:44:00+00:00   \n",
       "...                  ...                               ...   \n",
       "2621532          2621532  2021-07-16T05:40:11.870000+00:00   \n",
       "2626643          2626643         2021-07-19T04:50:00+00:00   \n",
       "2674832          2674832  2021-09-04T15:13:31.657000+00:00   \n",
       "2679778          2679778  2021-09-07T09:46:49.459999+00:00   \n",
       "2834360          2834360         2022-01-30T11:30:00+00:00   \n",
       "\n",
       "                              geometry  \\\n",
       "workorderid                              \n",
       "434549        POINT (9.85871 44.19513)   \n",
       "449895        POINT (9.87618 44.23608)   \n",
       "526117        POINT (9.84730 44.38188)   \n",
       "815762        POINT (9.86374 44.36673)   \n",
       "2621776       POINT (9.84420 44.38554)   \n",
       "...                                ...   \n",
       "2621532      POINT (10.30386 43.93762)   \n",
       "2626643      POINT (10.30334 43.94759)   \n",
       "2674832      POINT (10.29917 43.88345)   \n",
       "2679778       POINT (9.93401 44.33066)   \n",
       "2834360      POINT (10.30023 43.89871)   \n",
       "\n",
       "                                                      metadata  \n",
       "workorderid                                                     \n",
       "434549       {'id': '0', 'anno': 2015, 'civico': '0', 'comu...  \n",
       "449895       {'id': '1', 'anno': 2015, 'civico': '1', 'comu...  \n",
       "526117       {'id': '3', 'anno': 2015, 'civico': '00', 'com...  \n",
       "815762       {'id': '9', 'anno': 2016, 'civico': '', 'comun...  \n",
       "2621776      {'id': '44', 'anno': 2021, 'civico': None, 'co...  \n",
       "...                                                        ...  \n",
       "2621532      {'id': '34754', 'anno': 2021, 'civico': '51', ...  \n",
       "2626643      {'id': '34760', 'anno': 2021, 'civico': None, ...  \n",
       "2674832      {'id': '34873', 'anno': 2021, 'civico': None, ...  \n",
       "2679778      {'id': '34881', 'anno': 2021, 'civico': '24', ...  \n",
       "2834360      {'id': '35025', 'anno': 2022, 'civico': None, ...  \n",
       "\n",
       "[1713 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join them all, with primary columns and random metadata\n",
    "primary_cols = ['workorderid','reportdate','geometry']\n",
    "leaks = gpd.GeoDataFrame(pd.concat([leaks_data[primary_cols] for leaks_data in leaks_datas]), crs='epsg:4326')\n",
    "leaks['metadata'] = np.concatenate([leaks_data.drop(primary_cols,1).to_dict('records') for leaks_data in leaks_datas])\n",
    "leaks.index = leaks.workorderid\n",
    "leaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params\n",
    "\n",
    "Customise the values in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-16T06:09:45.267733Z",
     "start_time": "2017-03-16T14:09:45.240556+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# params\n",
    "bands = bands_srtm\n",
    "satellite = 'USGS/SRTMGL1_003'\n",
    "resolution_min = 10.0 # m\n",
    "\n",
    "# since the lowest res band is 60m and I want to capture neighbours I should get 6+ pixels\n",
    "pixel_length = 25.0\n",
    "\n",
    "# you need to tweak this until you pass the \"Test the distance need to get your rectangle\" cell\n",
    "fudge_distance_factor = -0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"notebook_name = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"notebook_name = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-17T14:30:44.254121",
     "start_time": "2017-01-17T14:30:44.250954"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scraping_earth_engine_srtm'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notebook_name='scraping_earth_engine_srtm'\n",
    "notebook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('../../../ricerca_perdite/data/scraped_satellite_images/USGS_SRTMGL1_003/tmp/'),\n",
       " Path('../../../ricerca_perdite/data/scraped_satellite_images/USGS_SRTMGL1_003'),\n",
       " Path('../../../ricerca_perdite/data/scraped_satellite_images/USGS_SRTMGL1_003/cache'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constant params, probobly don't change\n",
    "crs_grid = 3857 # keep this as auxilary sphere, this is the CRS the downloaded images will be in\n",
    "\n",
    "# init\n",
    "## init directories\n",
    "ts=arrow.utcnow().format('YYYYMMDD-HH-mm-ss')\n",
    "temp_dir = Path(root+'/data/scraped_satellite_images/'+satellite.replace(\"/\",\"_\")+'/tmp/')\n",
    "output_dir = Path(root+'/data/scraped_satellite_images/'+satellite.replace(\"/\",\"_\"))\n",
    "cache_dir = Path(output_dir+'/cache')\n",
    "output_dir.makedirs_p()\n",
    "temp_dir.makedirs_p()\n",
    "cache_dir.makedirs_p()\n",
    "\n",
    "## init logger\n",
    "logger = logging.getLogger(notebook_name)\n",
    "# logger.setLevel(logging.WARN)\n",
    "\n",
    "temp_dir, output_dir, cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record cofig in a json file\n",
    "metadata = dict(\n",
    "    notebook_name=notebook_name,\n",
    "    satellite=satellite,\n",
    "    pixel_length=pixel_length,\n",
    "    resolution_min=resolution_min,\n",
    "    bands=bands,\n",
    "    ts=ts,\n",
    "    crs_grid=crs_grid,\n",
    "    cache_dir=str(cache_dir),\n",
    "    temp_dir=str(temp_dir),\n",
    "    output_dir=str(output_dir),\n",
    ")\n",
    "metadata_file = output_dir.joinpath('script_metadata.json')\n",
    "json.dump(metadata, open(metadata_file,'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-16T06:09:52.672612Z",
     "start_time": "2017-03-16T14:09:45.283572+08:00"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Image',\n",
       " 'bands': [{'id': 'elevation',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'dimensions': [1296001, 417601],\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [0.0003, 0, -180.0001, 0, -0.0003, 60.0001]}],\n",
       " 'id': 'USGS/SRTMGL1_003',\n",
       " 'version': 1641990767055141,\n",
       " 'properties': {'system:visualization_0_min': '0.0',\n",
       "  'type_name': 'Image',\n",
       "  'keywords': ['dem',\n",
       "   'elevation',\n",
       "   'geophysical',\n",
       "   'nasa',\n",
       "   'srtm',\n",
       "   'topography',\n",
       "   'usgs'],\n",
       "  'thumb': 'https://mw1.google.com/ges/dd/images/SRTM90_V4_thumb.png',\n",
       "  'description': '<p>The Shuttle Radar Topography Mission (SRTM, see <a href=\"https://onlinelibrary.wiley.com/doi/10.1029/2005RG000183/full\">Farr\\net al. 2007</a>)\\ndigital elevation data is an international research effort that\\nobtained digital elevation models on a near-global scale. This\\nSRTM V3 product (SRTM Plus) is provided by NASA JPL\\nat a resolution of 1 arc-second (approximately 30m).</p><p>This dataset has undergone a void-filling process using open-source data\\n(ASTER GDEM2, GMTED2010, and NED), as opposed to other versions that\\ncontain voids or have been void-filled with commercial sources.\\nFor more information on the different versions see the\\n<a href=\"https://lpdaac.usgs.gov/documents/13/SRTM_Quick_Guide.pdf\">SRTM Quick Guide</a>.</p><p>Documentation:</p><ul><li><p><a href=\"https://lpdaac.usgs.gov/documents/179/SRTM_User_Guide_V3.pdf\">User&#39;s Guide</a></p></li><li><p><a href=\"https://lpdaac.usgs.gov/documents/13/SRTM_Quick_Guide.pdf\">General Documentation</a></p></li><li><p><a href=\"https://doi.org/10.1029/2005RG000183\">Algorithm Theoretical Basis Document (ATBD)</a></p></li></ul><p><b>Provider: <a href=\"https://cmr.earthdata.nasa.gov/search/concepts/C1000000240-LPDAAC_ECS.html\">NASA / USGS / JPL-Caltech</a></b><br><p><b>Bands</b><table class=\"eecat\"><tr><th scope=\"col\">Name</th><th scope=\"col\">Description</th></tr><tr><td>elevation</td><td><p>Elevation</p></td></tr></table><p><b>Terms of Use</b><br><p>Unless otherwise noted, images and video on JPL public\\nweb sites (public sites ending with a jpl.nasa.gov address) may\\nbe used for any purpose without prior permission. For more information\\nand exceptions visit the <a href=\"https://www.jpl.nasa.gov/imagepolicy/\">JPL Image Use Policy site</a>.</p><p><b>Suggested citation(s)</b><ul><li><p>Farr, T.G., Rosen, P.A., Caro, E., Crippen, R., Duren, R., Hensley,\\nS., Kobrick, M., Paller, M., Rodriguez, E., Roth, L., Seal, D.,\\nShaffer, S., Shimada, J., Umland, J., Werner, M., Oskin, M., Burbank,\\nD., and Alsdorf, D.E., 2007, The shuttle radar topography mission:\\nReviews of Geophysics, v. 45, no. 2, RG2004, at\\n<a href=\"https://doi.org/10.1029/2005RG000183\">https://doi.org/10.1029/2005RG000183</a>.</p></li></ul><style>\\n  table.eecat {\\n  border: 1px solid black;\\n  border-collapse: collapse;\\n  font-size: 13px;\\n  }\\n  table.eecat td, tr, th {\\n  text-align: left; vertical-align: top;\\n  border: 1px solid gray; padding: 3px;\\n  }\\n  td.nobreak { white-space: nowrap; }\\n</style>',\n",
       "  'source_tags': ['nasa', 'usgs'],\n",
       "  'visualization_0_max': '6000.0',\n",
       "  'title': 'NASA SRTM Digital Elevation 30m',\n",
       "  'product_tags': ['srtm', 'elevation', 'topography', 'dem', 'geophysical'],\n",
       "  'provider': 'NASA / USGS / JPL-Caltech',\n",
       "  'visualization_0_min': '0.0',\n",
       "  'visualization_0_name': 'Elevation',\n",
       "  'date_range': [950227200000, 951177600000],\n",
       "  'system:visualization_0_gamma': '1.6',\n",
       "  'period': 0,\n",
       "  'system:visualization_0_bands': 'elevation',\n",
       "  'provider_url': 'https://cmr.earthdata.nasa.gov/search/concepts/C1000000240-LPDAAC_ECS.html',\n",
       "  'visualization_0_gamma': '1.6',\n",
       "  'sample': 'https://mw1.google.com/ges/dd/images/SRTM90_V4_sample.png',\n",
       "  'tags': ['dem',\n",
       "   'elevation',\n",
       "   'geophysical',\n",
       "   'nasa',\n",
       "   'srtm',\n",
       "   'topography',\n",
       "   'usgs'],\n",
       "  'system:visualization_0_max': '6000.0',\n",
       "  'system:visualization_0_name': 'Elevation',\n",
       "  'system:asset_size': 132792638252,\n",
       "  'visualization_0_bands': 'elevation'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test earth-engine setup\n",
    "from oauth2client import crypt # should have not error\n",
    "import ee\n",
    "ee.Initialize() # should give no errors, if so follow instructions\n",
    "\n",
    "# test\n",
    "image = ee.Image(satellite)\n",
    "\n",
    "info = image.getInfo()\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# leak = leaks.iloc[[0]]\n",
    "# boundary = get_boundary(leak, distance=distance)\n",
    "\n",
    "# image = ee.Image(satellite)\n",
    "# elevation = image.clip(boundary)\n",
    "# slope = ee.Terrain.slope(image).clip(boundary)\n",
    "\n",
    "\n",
    "# # download_image(\n",
    "# #         slope, \n",
    "# #         scale=resolution_min, \n",
    "# #         crs=crs_grid, \n",
    "# #         name='prova',\n",
    "# #         cache_dir=cache_dir\n",
    "# #     )\n",
    "\n",
    "# elevation.getInfo(), slope.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-15T10:46:31.548298",
     "start_time": "2017-01-15T10:46:31.546367"
    }
   },
   "source": [
    "# Fetching images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-16T06:09:57.202371Z",
     "start_time": "2017-03-16T14:09:57.193264+08:00"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33184"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataset\n",
    "cache_file = 'sqlite:///{}'.format(cache_dir.dirname().joinpath('cache.db'))\n",
    "db = dataset.connect(cache_file)\n",
    "cache_table = db.get_table('cached_ids', primary_id='workorderid')\n",
    "\n",
    "def get_cached_ids():\n",
    "    return set(row['workorderid'] for row in cache_table.distinct('workorderid'))\n",
    "\n",
    "def init_cache(workorderid):\n",
    "    \"\"\"We will cache downloads in folders like 'id_after'\"\"\"\n",
    "    if workorderid:\n",
    "        try:\n",
    "            cache_table.insert(dict(workorderid=workorderid))\n",
    "        except:\n",
    "            db.rollback()\n",
    "        else:\n",
    "            db.commit()\n",
    "    return\n",
    "\n",
    "#Aggiunge il workorderid per il quale ho già l'immagine\n",
    "img_path = Path('../../data/scraped_satellite_images/'+satellite.replace(\"/\",\"_\")+'/cache/')\n",
    "for i in os.listdir(img_path):\n",
    "    init_cache(i.split('_')[0])\n",
    "\n",
    "# Conta il set di workorderid già scaricati\n",
    "len(get_cached_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # # Cancella dati dalla tabella\n",
    "# cache_table.delete()\n",
    "\n",
    "# Conta il set di workorderid che mancano da provare a scaricare\n",
    "leak_to_scrape = set(leaks.workorderid).difference(set(get_cached_ids()))\n",
    "\n",
    "len(leak_to_scrape)\n",
    "#leak_to_scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the distance need to get your rectangle\n",
    "\n",
    "Here we need to tweak `fudge_distance_factor` so that we get the image size of our choice. Start with zero and try -1, -0.5, -.25,0,0.25,0.5,0.75. This is to deal with rounding, projecting between CRS's etc. Don't worry the asserts below will yet you know when it's right.\n",
    "\n",
    "Occasionaly the problem might be that the leak is at the edge of the image, giving a cropped image. Ignore these rare cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-16T06:09:57.218046Z",
     "start_time": "2017-03-16T14:09:57.205020+08:00"
    }
   },
   "outputs": [],
   "source": [
    "distance = resolution_min*(pixel_length/2.00+fudge_distance_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-03-17T09:34:47.554Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f657cd7450d45f29ea2a7e1211cea31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import traceback\n",
    "cached_ids = get_cached_ids()\n",
    "\n",
    "\n",
    "def get_image_for_leak(i, cached_ids=cached_ids):\n",
    "    leak = leaks.loc[[i]]\n",
    "    repo_date_ts = arrow.get(leak.reportdate.values[0]).timestamp()\n",
    "    \n",
    "    # crappy way or recording that we tried this one\n",
    "    workorderid = leak.workorderid.values[0]\n",
    "    if workorderid in cached_ids:\n",
    "        logger.info('Skipping cached download for leak id %s ',workorderid)\n",
    "        return\n",
    "    \n",
    "    boundary = get_boundary(leak, distance=distance)\n",
    "    \n",
    "    srtm_img = ee.Image(satellite)\n",
    "\n",
    "    # download as save images    \n",
    "    logger.info('results for %s', workorderid)\n",
    "    \n",
    "    elevation = srtm_img.clip(boundary)\n",
    "    slope = ee.Terrain.slope(srtm_img).clip(boundary)\n",
    "    info = elevation.getInfo()\n",
    "    info['bands'].extend(slope.getInfo())\n",
    "    \n",
    "    name=str(workorderid)\n",
    "    \n",
    "    # scarico il DEM con le quote\n",
    "    path,files=download_image(\n",
    "        elevation, \n",
    "        scale=resolution_min, \n",
    "        crs=crs_grid, \n",
    "        name=name,\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "    \n",
    "    # scarico le pendenze con le quote\n",
    "    path,files=download_image(\n",
    "        slope, \n",
    "        scale=resolution_min, \n",
    "        crs=crs_grid, \n",
    "        name=name,\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "    # also save metadata so we can filter by date\n",
    "    with open(path.joinpath('metadata.json'), 'w') as fo:\n",
    "        metadata = dict(\n",
    "            image=info,\n",
    "            scale=resolution_min,\n",
    "            crs=crs_grid,\n",
    "            name=name,\n",
    "            distance=distance,\n",
    "            leak=json.loads(leak.to_json())\n",
    "        )\n",
    "        json.dump(metadata, fo)\n",
    "\n",
    "    cached_ids = init_cache(str(workorderid)) # so we know there where results\n",
    "    return\n",
    "\n",
    "leak_to_scrape = set(leaks.workorderid).difference(set(cached_ids))\n",
    "for i in tqdm(leak_to_scrape):\n",
    "    try:\n",
    "        get_image_for_leak(i)\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(i,e) # \"HTTP Error 429: unknown\"\n",
    "        traceback.print_stack()\n",
    "        if e.code == 429:\n",
    "            print('sleep for 13s')\n",
    "            time.sleep(13);\n",
    "    except ee.ee_exception.EEException as e:\n",
    "        print(i,e) # \"Earth Engine memory capacity exceeded.\"\n",
    "        traceback.print_stack()\n",
    "        ee.Initialize()\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(i,e) # \"File is not a zip file\"\n",
    "        traceback.print_stack()\n",
    "    except Exception as e:\n",
    "        print(i,e)\n",
    "        traceback.print_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c10c89e6fb748a78380e33894f354fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(33310, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Quality check dei dati\n",
    "\n",
    "X = []\n",
    "discarded = []\n",
    "\n",
    "for path in tqdm(cache_dir.listdir()):\n",
    "    files = [file.relpath(path) for file in path.listdir() if file.endswith('.tif')]\n",
    "    if files:      \n",
    "        # load data\n",
    "        data = tifs2np(path,files,bands=bands)\n",
    "        try:\n",
    "            assert data[bands.index('elevation')].max() < 2000 , 'la quota deve essere inferiore a 2000 m'\n",
    "        except Exception as exc:\n",
    "            print(path, exc)\n",
    "            discarded.append(data)\n",
    "        else:\n",
    "            X.append(data)\n",
    "\n",
    "len(X), len(discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.array(discarded,dtype=np.int16)[0][0]\n",
    "\n",
    "# import cv2\n",
    "# import imageio\n",
    "# import tifffile\n",
    "\n",
    "# def tifs2np_test(path, files, bands):\n",
    "#     \"\"\"Convert tifs to numpy array\"\"\"\n",
    "#     tifs = [f for f in files if f.endswith('.tif')]\n",
    "#     channels = {}\n",
    "#     for tif in tifs:\n",
    "#         band = tif.split('.')[-2]\n",
    "#         # read tif as float32\n",
    "#         #print(path.joinpath(tif))\n",
    "# #         x = cv2.imread(path.joinpath(tif), cv2.IMREAD_UNCHANGED) \n",
    "# #         x = plt.imread(path.joinpath(tif))#, format='tiff-pil') #, pilmode=\"F\") \n",
    "# #         x = imageio.imread(path.joinpath(tif), format='tiff-pil', pilmode=\"F\") \n",
    "#         x = tifffile.imread(path.joinpath(tif))#, format='tiff-pil', pilmode=\"F\") \n",
    "#         channels[band] = x\n",
    "\n",
    "#     pixel_length = x.shape[1]\n",
    "#     pixel_width = x.shape[0]\n",
    "#     data = []\n",
    "#     for band in bands:\n",
    "#         if band not in channels:\n",
    "#             channels[band] = np.zeros((pixel_width, pixel_length))\n",
    "#         data.append(channels[band])\n",
    "#     return np.array(data)\n",
    "\n",
    "\n",
    "# path_test = Path('../../../ricerca_perdite/data/scraped_satellite_images/USGS_SRTMGL1_003/cache/1000409_3857_10.0')\n",
    "# files_test = [file.relpath(path_test) for file in path_test.listdir() if file.endswith('.tif')]\n",
    "# print(files_test)\n",
    "# data_test = tifs2np_test(path_test, files_test, bands=bands)\n",
    "\n",
    "# data_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite",
   "language": "python",
   "name": "satellite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {
    "height": "96px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
